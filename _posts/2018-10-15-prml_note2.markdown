---
layout:     post
title:      "PRML学习笔记（二）"
subtitle:   "第二章 概率分布"
date:       2018-10-15 00:15:18
author:     "Pelhans"
header-img: "img/prml.jpg"
header-mask: 0.3 
catalog:    true
tags:
    - PRML
---


> PRML 和 ESL 的学习基本上是学十得一。稳扎稳打再来一次

* TOC
{:toc}

# 概率分布

## 2.1 二元变量
### 2.1.0.1 伯努利分布

在给定有限次观测数据的前提下，对随机变量x的概率分布p(x)进行建模。这个问题被称为密度估计。

当一个变量的取值只有两种可能，如0或1这种时。其中取1的概率被记做$\mu$。因此：

$$ p(x = 1 | \mu) = \mu $$

因此x的概率分布就是伯努利分布，公式表达为：

$$ Bern(x | \mu) = \mu^{x}(1-\mu)^{1-x} $$

其均值和方差为：

$$ E[x] = \mu $$

$$ var[x] = \mu(1-\mu) $$

假设观测数据是i.i.d.的，那么对应的似然函数为：

$$ p(D | \mu) = \prod_{n=1}^{N}p(x_{n} | \mu) = \prod_{n=1}^{N}\mu^{x_{n}}(1-\mu)^{1-x_{n}} $$

通过对对数似然求导得到概率的最大似然估计值：

$$ \mu_{ML} = \frac{1}{N}\sum_{n=1}{N}x_{n} $$

### 2.1.0.1 二项分布

二项分布简单来说就是进行多次实验的伯努利分布。学术上来讲它是求解在给定数据集规模N的条件下，x=1的观测出现数量m的概率分布。公式表述为：

$$ Bin(m | N,\mu) = \frac{N!}{(N-m)!m!}\mu^{m}(1-\mu)^{N-m} $$

对于独立的事件，加和的均值等于均值的加和，嘉禾的方差等于方差的加和。

### 2.1.1 Beta分布

现在我们要求解二项分布中$\mu$的最大似然解，即数据集中x=1出现的比例。为了从贝叶斯的角度看待这个问题，我们需要引入一个关于$\mu$的先验分布$p(\mu)$。

这里首先介绍一下**共轭性，它值一个概率分布的后验概率与先验分布具有相同的函数形式，它能使贝叶斯分析得到极大的简化**。

对于二项分布来说，由于似然函数为$\mu^{x}(1-\mu)^{1-x}$的形式，那么对应的先验分布也得具有这个形式才能满足共轭性，因此我们选择先验分布为Beta分布：

$$ Beta(\mu | a,b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1} $$

其中a，b为超参数。Beta分布对应的均值和方差为：

$$ E[\mu] = \frac{a}{a + b} $$

$$ var[\mu] = \frac{ab}{(a+b)^{2}(a + b + 1)} $$

因为先验函数与后验函数满足共轭性，因此后验函数的概率分布为(已归一化)：

$$ p(\mu | m,l,a,b) = \frac{\Gamma(m+a+l+b)}{\Gamma(m+a)\Gamma(l+b)}\mu^{m+a-1}(1-\mu)^{l+b-1} $$

如果我们的目标是尽可能好的预测下一次实验的的输出，那么我们必须估计给定观测数据集D的情况下，x的预测分布。其形式为：

$$ p(x = 1 | D) = \int_{0}^{1}p(x=1 | \mu)p(\mu | D)d\mu = \int_{0}^{1}\mu p(\mu | D)d\mu = E[\mu | D] $$

将前面求得的对应项带入得：

$$ p(x = 1 | D) = \frac{m+a}{m+a+l+b} $$

可以看到，当m,l趋于无穷大时，上式变成了最大似然的结果。因此**贝叶斯的结果和最大似然的结果在数据集的规模区域无穷的情况下会统一到一起**。

并且由Beta分布的方差可知，**在平均来看，随着我们观测到越来越多的数据，后验概率的不确定性将会持续的下降**。公式表示为：

$$ E_{\theta}(\theta) = E_{D}[E_{\theta}[\theta | D]] $$

$$ var_{\theta}[\theta] = E_{D}[var_{\theta}[\theta | D]] + var_{D}[E_{\theta}[\theta | D]] $$

可以看到，**$\theta$的后验方差小于先验的方差。后验均值的方差越大，这个方差的减小就越大**。需要注意的是上式为平均结果，对于一个特定的数据集，有可能后验方差大于先验方差。

## 2.2 多项式变量


